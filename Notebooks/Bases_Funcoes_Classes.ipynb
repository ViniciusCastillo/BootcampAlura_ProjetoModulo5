{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bases_Funcoes_Classes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMl4SR5C2HIEactjolzwuqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViniciusCastillo/BootcampAlura_ProjetoModulo5/blob/main/Notebooks/Bases_Funcoes_Classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook dedicado ao tratamento de dados, criação de funções e classes\n",
        "\n",
        "Neste notebook iremos importar as bibliotecas necessárias, fazer o tratamento inicial dos dados e criar as funções e classes necessárias para as avaliações do projeto"
      ],
      "metadata": {
        "id": "j8Ka6mraRzWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando as bibliotecas"
      ],
      "metadata": {
        "id": "2N5L8NS6TBXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0tE0CU1FQgsV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, classification_report, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from joblib import dump, load"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando e tratando os dados\n"
      ],
      "metadata": {
        "id": "7YQkvJh_THPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando a base de dados\n",
        "A base original está neste desafio do [Kaggle](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19)"
      ],
      "metadata": {
        "id": "ufDCawh8TNWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_excel(\"https://github.com/ViniciusCastillo/BootcampAlura_ProjetoModulo5/blob/main/dados/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")"
      ],
      "metadata": {
        "id": "QLI-WsarRLHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratando os dados"
      ],
      "metadata": {
        "id": "PBE-23KDTgX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primeiro passo: criar as bases dados_tratados e dados_LE\n",
        "Aqui será realizado alguns tratamentos:\n",
        "* Retirar as linhas com marcação de UTI = 1\n",
        "* Remarcar a coluna ICU (UTI em inglês), conforme qual visita de pacientes (PATIENT_VISIT_IDENTIFIER) chegou algum momento na UTI, independente da janela (campo WINDOW), em todas as janelas.\n",
        "* Tratando os dados que não estão disponíveis com base na medição anterior ou posterior.\n",
        "** Caso ainda sobre dados indisponível, as linhas onde eles estão serão excluídas. \n",
        "** Isso se o limite de 10% da base for atendido, caso contrário irá informar o problema e não excluirá os dados.\n",
        "* Reinicia o index para a numeração ficar de 0 até o número de elementos.\n",
        "\n",
        "A base dados_LE irá alterar o formato do campo AGE_PERCENTIL para valores numéricos com base na função [LabelEncoder() do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
        "\n",
        "Caso a base passe a ter mais de um campo categórico de texto a base dados_LE não será criada e será comunicado o ocorrido."
      ],
      "metadata": {
        "id": "XrkVq0-wTnNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tratamento da Base com Label Encoder\")\n",
        "\n",
        "pacientes_UTI = dados[['PATIENT_VISIT_IDENTIFIER','ICU']].query('ICU == 1').groupby('PATIENT_VISIT_IDENTIFIER').min()\n",
        "dados_tratados = dados.query('ICU != 1').drop('ICU', axis=1)\n",
        "dados_tratados = dados_tratados.join(pacientes_UTI, on='PATIENT_VISIT_IDENTIFIER', how='left')\n",
        "dados_tratados['ICU'] = dados_tratados['ICU'].fillna(0) \n",
        "print(\"\\nRemovemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\")\n",
        "print(f\"Distribuição de ICU na base tratada (%)\\n{dados_tratados['ICU'].value_counts(normalize=True)*100}\")\n",
        "\n",
        "features_continuas_colunas = dados_tratados.iloc[:, 13:-2].columns\n",
        "features_continuas = dados_tratados.groupby(\"PATIENT_VISIT_IDENTIFIER\",as_index=False)[features_continuas_colunas].fillna(method='bfill').fillna(method='ffill')\n",
        "features_categoricas = dados_tratados.iloc[:, :13]\n",
        "saida = dados_tratados.iloc[:, -2:]\n",
        "dados_tratados = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\n",
        "dados_tratados.columns = dados.columns\n",
        "print(\"\\nAjustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\")\n",
        "\n",
        "descricao = dados_tratados.describe().T\n",
        "colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "if len(colunas_sem_variacao) !=0:\n",
        "  dados_tratados.drop(colunas_sem_variacao, axis=1)\n",
        "  print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "linhas_com_nam = dados_tratados.describe(include='all').loc['count'].max()-dados_tratados.describe(include='all').loc['count'].min()\n",
        "if linhas_com_nam !=0:\n",
        "  if linhas_com_nam <= len(dados_tratados)*.1:\n",
        "    dados_tratados.dropna(inplace=True)\n",
        "    print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) foram eliminadas\")\n",
        "  else:\n",
        "    print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) precisam ser tratadas\")\n",
        "\n",
        "dados_tratados.reset_index(drop=True, inplace=True)\n",
        "print(f\"\\nO index foi resetado: {dados_tratados.index}\")\n",
        "\n",
        "colunas_categoricas = list(set(dados_tratados.columns)-set(dados_tratados.describe().columns)-{'WINDOW'})\n",
        "if len(colunas_categoricas) ==1:\n",
        "  LE = LabelEncoder()\n",
        "  LE.fit(np.ravel(dados_tratados[colunas_categoricas]))\n",
        "  dados_LE = dados_tratados.copy()\n",
        "  dados_LE[colunas_categoricas] = LE.transform(np.ravel(dados_LE[colunas_categoricas]))\n",
        "  print(f\"\\nColuna com objeto categórico ({colunas_categoricas[0]}) foi transformada em numérica no DataFrame dados_LE.\\nFormato: {dados_LE.shape}\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")\n",
        "  \n",
        "print(f\"\\nFormato final do DataFrame dados_tratados: {dados_tratados.shape}\")"
      ],
      "metadata": {
        "id": "-LRVj2TTRPV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segundo passo: criar a base dados_OHE\n",
        "A base dados_OHE irá alterar o formato do campo AGE_PERCENTIL para valores numéricos com base na função [OneHotEncoder() do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). Este modelo transforma o campo em diversas colunas, uma para cada categoria.\n",
        "\n",
        "Caso a base passe a ter mais de um campo categórico de texto a base dados_OHE não será criada e será comunicado o ocorrido."
      ],
      "metadata": {
        "id": "LOvd4fNkXedv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tratamento da Base com One Hot Encoder\")\n",
        "\n",
        "if len(colunas_categoricas) ==1:\n",
        "  categorica = np.array(dados_tratados[colunas_categoricas]).reshape(-1, 1)\n",
        "  OHE = OneHotEncoder()\n",
        "  categorica_OHE = pd.DataFrame(OHE.fit_transform(categorica).toarray())\n",
        "  dados_OHE = pd.concat([dados_tratados.drop(colunas_categoricas, axis=1), categorica_OHE], ignore_index=True, axis=1)\n",
        "  colunas = list(dados_tratados.columns)\n",
        "  colunas.remove(colunas_categoricas[0])\n",
        "  colunas_novas = list(dados_tratados[colunas_categoricas[0]].unique())\n",
        "  colunas_novas.sort()\n",
        "  colunas.extend(colunas_novas)\n",
        "  dados_OHE.columns = colunas\n",
        "  print(f\"\\nTrocamos o campo AGE_PERCENTIL pelos campos binários {', '.join(colunas_novas)}\")\n",
        "  print(f\"\\nFormato final do DataFrame dados_OHE: {dados_OHE.shape}\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")"
      ],
      "metadata": {
        "id": "hiwZFDzYRXAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções"
      ],
      "metadata": {
        "id": "H496p28mYjRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### adiciona_janelas (<font color = 'yellow'>dados_anterior</font>, <font color = 'yellow'>dados_janela</font>, <font color = 'yellow'>colunas</font>=<font color = 'blue'>features_continuas_colunas</font>)\n",
        "Mistura a base de duas janelas, permitindo fazer a avaliação de mais de uma janela para melhorar as previsões conforme o tempo de permanencia do visitante for aumentando."
      ],
      "metadata": {
        "id": "KBqSaPPDYvdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adiciona_janela(dados_anterior, dados_janela, colunas=features_continuas_colunas):\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ENTRADAS\n",
        "  --------\n",
        "  dados_anterior: DataFrame\n",
        "      dados da janela atual que está sendo observada. Por exemplo o filtro WINDOW == '0-2'\n",
        "\n",
        "  dados_janela: DataFrame\n",
        "      dados da janela que será adcionada. Seguindo o exemplo o filtro WINDOW == '2-4'\n",
        "\n",
        "  colunas: list\n",
        "      lista de colunas que devem ser adiciondos, não deveríamos adicionar novamente os dados categóricos por \n",
        "      exemplo. Por isso por padrão são utilizadas as features continuas\n",
        "  ________________________________________________________________________________________________________________\n",
        "  SAIDAS\n",
        "  ------\n",
        "  DataFrame\n",
        "      Nova base de dados adcionando as colunas seleciondas, adicionando a variação delas contra a janela anterior \n",
        "      e removendo o que não for útil\n",
        "  \"\"\"\n",
        "  d1 = dados_janela.set_index('PATIENT_VISIT_IDENTIFIER')\n",
        "  d2 = dados_anterior.set_index('PATIENT_VISIT_IDENTIFIER')\n",
        "  sufixo = ' ' + str(dados_anterior.loc[0,\"WINDOW\"])\n",
        "  dados_novo = d1.join(d2[colunas], how='left', rsuffix=sufixo).reset_index()\n",
        "\n",
        "  for _ in colunas:\n",
        "    coluna = 'var ' + _ + sufixo\n",
        "    coluna_ = _ + sufixo\n",
        "    dados_novo[coluna] = dados_novo[_] - dados_novo[coluna_]\n",
        "\n",
        "  descricao = dados_novo.describe().T\n",
        "  colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "  if len(colunas_sem_variacao) !=0:\n",
        "    dados_novo.drop(colunas_sem_variacao, axis=1)\n",
        "    print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "  linhas_com_nam = dados_novo.describe(include='all').loc['count'].max()-dados_novo.describe(include='all').loc['count'].min()\n",
        "  if linhas_com_nam !=0:\n",
        "    if linhas_com_nam <= len(dados_novo)*.1:\n",
        "      dados_novo.dropna(inplace=True)\n",
        "      print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_novo):.2%} do total) foram eliminadas\")\n",
        "    else:\n",
        "      print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_novo):.2%} do total) precisam ser tratadas\")\n",
        "  print(f'\\nBase nova de tamanho: {dados_novo.shape}')\n",
        "  return dados_novo"
      ],
      "metadata": {
        "id": "0tHJpYKtYkNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}