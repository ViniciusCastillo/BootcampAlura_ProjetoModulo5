{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bases_Funcoes_Classes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoe5nn/DRFUC4uit/G4SM4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViniciusCastillo/BootcampAlura_ProjetoModulo5/blob/main/Notebooks/Bases_Funcoes_Classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook dedicado ao tratamento de dados, criação de funções e classes\n",
        "\n",
        "Neste notebook iremos importar as bibliotecas necessárias, fazer o tratamento inicial dos dados e criar as funções e classes necessárias para as avaliações do projeto\n",
        "\n",
        "Se você não leu, recomendo que leia o [Readme](https://github.com/ViniciusCastillo/BootcampAlura_ProjetoModulo5/blob/main/README.md). E se quiser ver as análises para a seleção dos modelos veja este [notebook](https://github.com/ViniciusCastillo/BootcampAlura_ProjetoModulo5/blob/main/Notebooks/Seleciona_Modelo.ipynb)."
      ],
      "metadata": {
        "id": "j8Ka6mraRzWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando as bibliotecas"
      ],
      "metadata": {
        "id": "2N5L8NS6TBXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tE0CU1FQgsV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, Normalizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, classification_report, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from joblib import dump, load"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando e tratando os dados\n"
      ],
      "metadata": {
        "id": "7YQkvJh_THPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando a base de dados\n",
        "A base original está neste desafio do [Kaggle](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19)"
      ],
      "metadata": {
        "id": "ufDCawh8TNWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_excel(\"https://github.com/ViniciusCastillo/BootcampAlura_ProjetoModulo5/blob/main/dados/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")"
      ],
      "metadata": {
        "id": "QLI-WsarRLHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratando os dados"
      ],
      "metadata": {
        "id": "PBE-23KDTgX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primeiro passo: criar as bases dados_tratados e dados_LE\n",
        "Aqui será realizado alguns tratamentos:\n",
        "* Retirar as linhas com marcação de UTI = 1\n",
        "* Remarcar a coluna ICU (UTI em inglês), com a informação se o paciente visitante (PATIENT_VISIT_IDENTIFIER) chegou na UTI, independente da janela (campo WINDOW)\n",
        "* Tratar os dados que não estão disponíveis com base na medição anterior ou posterior\n",
        "  * Caso ainda sobre valores indisponíveis, as linhas serão excluídas\n",
        "* Remover as colunas que tem o mesmo valor em todas as linhas da base\n",
        "* Reiniciar o index para a numeração ficar de 0 até o número de linhas.\n",
        "* Transformar o campo demográfico 'AGE PERCENTIL' que está em formato de texto\n",
        "\n",
        "A base dados_LE irá alterar o formato do campo AGE_PERCENTIL para valores numéricos com base na função [LabelEncoder() do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
        "\n",
        "Caso a base passe a ter mais de um campo categórico de texto a base dados_LE não será criada e será comunicado o ocorrido."
      ],
      "metadata": {
        "id": "XrkVq0-wTnNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTratamento da Base com Label Encoder\")\n",
        "\n",
        "pacientes_UTI = dados[['PATIENT_VISIT_IDENTIFIER','ICU']].query('ICU == 1').groupby('PATIENT_VISIT_IDENTIFIER').min()\n",
        "dados_tratados = dados.query('ICU != 1').drop('ICU', axis=1)\n",
        "dados_tratados = dados_tratados.join(pacientes_UTI, on='PATIENT_VISIT_IDENTIFIER', how='left')\n",
        "dados_tratados['ICU'] = dados_tratados['ICU'].fillna(0) \n",
        "print(\"\\nRemovemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\")\n",
        "print(f\"Distribuição de ICU na base tratada (%)\\n{dados_tratados['ICU'].value_counts(normalize=True)*100}\")\n",
        "\n",
        "features_continuas_colunas = dados_tratados.iloc[:, 13:-2].columns\n",
        "features_continuas = dados_tratados.groupby(\"PATIENT_VISIT_IDENTIFIER\",as_index=False)[features_continuas_colunas].fillna(method='bfill').fillna(method='ffill')\n",
        "features_categoricas = dados_tratados.iloc[:, :13]\n",
        "saida = dados_tratados.iloc[:, -2:]\n",
        "dados_tratados = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\n",
        "dados_tratados.columns = dados.columns\n",
        "print(\"\\nAjustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\")\n",
        "\n",
        "descricao = dados_tratados.describe().T\n",
        "colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "if len(colunas_sem_variacao) !=0:\n",
        "  dados_tratados.drop(colunas_sem_variacao, axis=1)\n",
        "  print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "linhas_com_nam = dados_tratados.describe(include='all').loc['count'].max()-dados_tratados.describe(include='all').loc['count'].min()\n",
        "if linhas_com_nam !=0:\n",
        "  if linhas_com_nam <= len(dados_tratados)*.1:\n",
        "    dados_tratados.dropna(inplace=True)\n",
        "    print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) foram eliminadas\")\n",
        "  else:\n",
        "    print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) precisam ser tratadas\")\n",
        "\n",
        "dados_tratados.reset_index(drop=True, inplace=True)\n",
        "print(f\"\\nO index foi resetado: {dados_tratados.index}\")\n",
        "\n",
        "colunas_categoricas = list(set(dados_tratados.columns)-set(dados_tratados.describe().columns)-{'WINDOW'})\n",
        "if len(colunas_categoricas) ==1:\n",
        "  LE = LabelEncoder()\n",
        "  LE.fit(np.ravel(dados_tratados[colunas_categoricas]))\n",
        "  dados_LE = dados_tratados.copy()\n",
        "  dados_LE[colunas_categoricas] = LE.transform(np.ravel(dados_LE[colunas_categoricas]))\n",
        "  print(f\"\\nColuna com objeto categórico ({colunas_categoricas[0]}) foi transformada em numérica no DataFrame dados_LE.\\nFormato: {dados_LE.shape}\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")\n",
        "  \n",
        "print(f\"\\nFormato final do DataFrame dados_tratados: {dados_tratados.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LRVj2TTRPV4",
        "outputId": "bc4e6e5c-6d3d-46b9-865d-2979245d702f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tratamento da Base com Label Encoder\n",
            "\n",
            "Removemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\n",
            "Distribuição de ICU na base tratada (%)\n",
            "0.0    67.375887\n",
            "1.0    32.624113\n",
            "Name: ICU, dtype: float64\n",
            "\n",
            "Ajustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\n",
            "\n",
            "Removemos as colunas que os valores são iguais para todas as linhas\n",
            "\n",
            "As linhas ainda com Nam (5.0 linhas, 0.36% do total) foram eliminadas\n",
            "\n",
            "O index foi resetado: RangeIndex(start=0, stop=1405, step=1)\n",
            "\n",
            "Coluna com objeto categórico (AGE_PERCENTIL) foi transformada em numérica no DataFrame dados_LE.\n",
            "Formato: (1405, 231)\n",
            "\n",
            "Formato final do DataFrame dados_tratados: (1405, 231)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segundo passo: criar a base dados_OHE\n",
        "A base dados_OHE irá alterar o formato do campo AGE_PERCENTIL para valores numéricos com base na função [OneHotEncoder() do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). Este modelo transforma o campo em diversas colunas binárias, uma para cada categoria.\n",
        "\n",
        "Caso a base passe a ter mais de um campo categórico de texto a base dados_OHE não será criada e será comunicado o ocorrido."
      ],
      "metadata": {
        "id": "LOvd4fNkXedv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTratamento da Base com One Hot Encoder\")\n",
        "\n",
        "if len(colunas_categoricas) ==1:\n",
        "  categorica = np.array(dados_tratados[colunas_categoricas]).reshape(-1, 1)\n",
        "  OHE = OneHotEncoder()\n",
        "  categorica_OHE = pd.DataFrame(OHE.fit_transform(categorica).toarray())\n",
        "  dados_OHE = pd.concat([dados_tratados.drop(colunas_categoricas, axis=1), categorica_OHE], ignore_index=True, axis=1)\n",
        "  colunas = list(dados_tratados.columns)\n",
        "  colunas.remove(colunas_categoricas[0])\n",
        "  colunas_novas = list(dados_tratados[colunas_categoricas[0]].unique())\n",
        "  colunas_novas.sort()\n",
        "  colunas.extend(colunas_novas)\n",
        "  dados_OHE.columns = colunas\n",
        "  print(f\"\\nTrocamos o campo AGE_PERCENTIL pelos campos binários {', '.join(colunas_novas)}\")\n",
        "  print(f\"\\nFormato final do DataFrame dados_OHE: {dados_OHE.shape}\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiwZFDzYRXAO",
        "outputId": "081b3adc-7cbb-4fdb-9aaa-20843cf4dd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tratamento da Base com One Hot Encoder\n",
            "\n",
            "Trocamos o campo AGE_PERCENTIL pelos campos binários 10th, 20th, 30th, 40th, 50th, 60th, 70th, 80th, 90th, Above 90th\n",
            "\n",
            "Formato final do DataFrame dados_OHE: (1405, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções"
      ],
      "metadata": {
        "id": "H496p28mYjRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### adiciona_janelas\n",
        "Junta a base de duas janelas, permitindo fazer a avaliação de janelas seguintes a inicial, conforme o tempo de permanencia do visitante for aumentando."
      ],
      "metadata": {
        "id": "KBqSaPPDYvdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adiciona_janela(dados_anterior, dados_janela, colunas=features_continuas_colunas):\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ENTRADAS\n",
        "  --------\n",
        "  dados_anterior: DataFrame\n",
        "      dados da janela atual que está sendo observada. Por exemplo o filtro WINDOW == '0-2'\n",
        "\n",
        "  dados_janela: DataFrame\n",
        "      dados da janela que será adcionada. Seguindo o exemplo o filtro WINDOW == '2-4'\n",
        "\n",
        "  colunas: list\n",
        "      lista de colunas que devem ser adiciondos, não deveríamos adicionar novamente os dados categóricos por \n",
        "      exemplo. Por isso, por padrão são utilizadas as features continuas\n",
        "  ________________________________________________________________________________________________________________\n",
        "  SAIDAS\n",
        "  ------\n",
        "  DataFrame\n",
        "      Nova base de dados partindo do dados_janela e adcionando as colunas seleciondas da base dados_anterior, \n",
        "      também adicionando a variação dessas colunas contra a janela anterior e removendo o que não for útil\n",
        "  \"\"\"\n",
        "  d1 = dados_janela.set_index('PATIENT_VISIT_IDENTIFIER')\n",
        "  d2 = dados_anterior.set_index('PATIENT_VISIT_IDENTIFIER')\n",
        "  sufixo = ' ' + str(dados_anterior.loc[0,\"WINDOW\"])\n",
        "  dados_novo = d1.join(d2[colunas], how='left', rsuffix=sufixo).reset_index()\n",
        "\n",
        "  for _ in colunas:\n",
        "    coluna = 'var ' + _ + sufixo\n",
        "    coluna_ = _ + sufixo\n",
        "    dados_novo[coluna] = dados_novo[_] - dados_novo[coluna_]\n",
        "\n",
        "  descricao = dados_novo.describe().T\n",
        "  colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "  if len(colunas_sem_variacao) !=0:\n",
        "    dados_novo.drop(colunas_sem_variacao, axis=1)\n",
        "    print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "  linhas_com_nam = dados_novo.describe(include='all').loc['count'].max()-dados_novo.describe(include='all').loc['count'].min()\n",
        "  if linhas_com_nam !=0:\n",
        "    if linhas_com_nam <= len(dados_novo)*.1:\n",
        "      dados_novo.dropna(inplace=True)\n",
        "      print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_novo):.2%} do total) foram eliminadas\")\n",
        "    else:\n",
        "      print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_novo):.2%} do total) precisam ser tratadas\")\n",
        "  print(f'\\nBase nova de tamanho: {dados_novo.shape}')\n",
        "  return dados_novo"
      ],
      "metadata": {
        "id": "0tHJpYKtYkNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "kZy12DzTeqKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### remove_corr\n",
        "classe utilizada para seleção de dados, removendo os que tem alta correlação entre si e baixa correlação com o y alvo."
      ],
      "metadata": {
        "id": "X5sglS0sej2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class remove_corr(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  Seleciona os dados com base na correlação deles entre si (dentro do X) e com a variável objetivo (y)\n",
        "  ________________________________________________________________________________________________________________\n",
        "  PARAMETROS\n",
        "  ----------\n",
        "  corr_maxima: float\n",
        "      define o máximo valor permitido para as correlações entre as variávies de X, acima disso as variáveris X\n",
        "      serão desconsideradas (mantendo apenas uma entre as duas que tem alta correlação entre si)\n",
        "\n",
        "  corr_minima: float\n",
        "      define o valor minimo para a correlação entre o y e as variaveis de X, abaixo disso as variaves de X \n",
        "      serão eliminadas\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ATRIBUTOS\n",
        "  ---------\n",
        "  excluir: list\n",
        "      Lista das colunas/variáveris a serem excluidas do X, criado pelo método fit()\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__( self, corr_maxima = 0.95, corr_minima=0.05):\n",
        "    self.corr_maxima = corr_maxima\n",
        "    self.corr_minima = corr_minima\n",
        "\n",
        "  def fit( self, X, y):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    faz o fit do modelo, salvando uma lista de colunas/variáveris a serem excluidas do X\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADAS\n",
        "    ----------\n",
        "    X: DataFrame\n",
        "        a base das variáveis utilizadas para tentar definir o y\n",
        "\n",
        "    y: Series\n",
        "        a variável objetivo que buscamos prever\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    objeto da classe remove_corr\n",
        "        modelo de seleção já configurado aguardando a utilização do método transform()\n",
        "        \n",
        "    \"\"\"\n",
        "    corr = X.corr().abs()\n",
        "    corr_diagonal = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
        "    self.excluir = [coluna for coluna in corr_diagonal.columns if any(corr_diagonal[coluna] > self.corr_maxima)]\n",
        "    X_ = X.drop(self.excluir, axis=1)\n",
        "    X_ = X_.join(y, how='left')\n",
        "    X_corr = X_.corr().abs()\n",
        "    self.excluir.extend(list(X_corr.query('ICU < @self.corr_minima')['ICU'].index))\n",
        "\n",
        "    return self \n",
        "    \n",
        "  def transform(self, X, y = None):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    remove as colunas/variáveis definidas pelo método fit() do DataFrame X passado\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADAS\n",
        "    ----------\n",
        "    X: DataFrame\n",
        "        a base das variáveis utilizadas para tentar encontrar definir o y que será transformada\n",
        "\n",
        "    y: Series\n",
        "        a variável objetivo que buscamos prever. \n",
        "        Não será utilizada e não precisa ser passada.\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    DataFrame\n",
        "        novo DataFrame do X após a exclusão das colunas/variáveis definidas no fit()\n",
        "        \n",
        "    \"\"\"\n",
        "    X = X.drop(self.excluir, axis=1)\n",
        "    return X"
      ],
      "metadata": {
        "id": "hK35PxW5eyXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### seleciona_modelo\n",
        "classe para testar as melhores configurações e criar um pipeline dado um modelo de classificação definido"
      ],
      "metadata": {
        "id": "rwEcIemKgBAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class seleciona_modelo():\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  A partir de um modelo de classificação definido, está classe permite você testar diversas opções de pipelines\n",
        "  e configurações do modelo escolhido, com o objetivo de encontrar o que possuí maior precisão para definir o y.\n",
        "\n",
        "  Além disso, após os testes podemos criar o melhor pipeline, treina-lo, testa-lo e salva-lo em um aquivo\n",
        "  ________________________________________________________________________________________________________________\n",
        "  PARAMETROS\n",
        "  ----------\n",
        "  modelo: modelo de classificação do sklearn\n",
        "      modelo que será utilizado nos testes do pipeline e de seus paramêtros, bem como no pipeline final\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ATRIBUTOS\n",
        "  ---------\n",
        "  metrica: str\n",
        "      metrica utilizada nos cálculos comparativos dos testes, definida no método testa_parametros()\n",
        "  \n",
        "  Xs: dict\n",
        "      dicionários dos Xs testados com base nas bases envidas no método testa_parametros()\n",
        "\n",
        "  ys: dict\n",
        "      dicionários dos ys testados com base nas bases envidas no método testa_parametros()\n",
        "\n",
        "  resultados: DataFrame\n",
        "      DataFrame com os resultados do método testa_parametro(), tem os resultados e as etapas do pipeline utilizado\n",
        "\n",
        "  indice: int\n",
        "      indice da linha dos resultados que iremos utilizar para criar o pipeline final, criado no método cria_pipeline()\n",
        "\n",
        "  pipe: Pipeline\n",
        "      pipeline final criado no método cria_pipeline()\n",
        "\n",
        "  base: str\n",
        "      Nome da base que teve o melhor resultado, para utilização na avaliação das métricas do pipeline final.\n",
        "      Criada no método cria_pipeline()\n",
        "  \n",
        "  modelo_final: Pipeline\n",
        "      modelo do pipeline utilizado para ser salvo no arquivo. \n",
        "      Criado no método cria_modelo_final() ou cria_salva_modelo_final()\n",
        "  \"\"\"\n",
        "  def __init__( self, modelo):\n",
        "    self.modelo = modelo\n",
        "\n",
        "  def testa_parametros(self, parametros, lista_dados=[(dados_LE, 'LE')], lista_reescalas=['nenhuma'], \n",
        "                      selecao_menor=-30, selecao_maior=30, passo=30, n_splits = 5, n_repeats=10, metrica='roc_auc'):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    testa deiveros parametros, seleções e reescalas conforme solicitação do usuário\n",
        "\n",
        "    por padrão todas os testes colocam no lógica do pipeline um objeto da classe remove_corr(), devido a testes\n",
        "    anteriores demonstrarem a eficácia da utilização desta seleção prévia\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADAS\n",
        "    --------\n",
        "    parametros: dict\n",
        "        dicionário com os parametros do modelo que queremos testar. lembrando que o formato de cada item é o nome \n",
        "        parametro e a lista de valores que se deseja testar\n",
        "\n",
        "    lista_dados: list de tuplas\n",
        "        lista contendo tuplas com a base que queremos testar (DataFrame) e nome que iremos identifica-la (str)\n",
        "    \n",
        "    lista_reescalas: list\n",
        "        lista deve conter as funções de reescala que queremos utilizar ou a string 'nenhuma'\n",
        "    \n",
        "    selecao_menor: int\n",
        "        valor do percentual (será divido por 100) que queremos distanciar da média no paramêtro threshold da função\n",
        "        SelectFromModel. Este é o valor inferior do range que será testado.\n",
        "        Os valores menores ou iguais a -100 do range farão com que não se aplique essa segunda seleção no número\n",
        "    \n",
        "    selecao_maior: int\n",
        "        valor do percentual (será divido por 100) que queremos distanciar da média no paramêtro threshold da função\n",
        "        SelectFromModel. Este é o valor superio do range que será testado.\n",
        "        Os valores menores ou iguais a -100 do range farão com que não se aplique essa segunda seleção no número\n",
        "\n",
        "    passo: int\n",
        "        valor do aumento gradual que será colocado na selecao_menor até chegar na selecao_maior dentro do range.\n",
        "    \n",
        "    n_splits: int\n",
        "        número de divisões que será realizada no objeto RepeatedStratifiedKFold durante os testes\n",
        "\n",
        "    n_repeats: int\n",
        "        número de repetições que será realizada no objeto RepeatedStratifiedKFold durante os testes\n",
        "    \n",
        "    metrica: str\n",
        "        metrica utilizada nos cálculos comparativos dos testes\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    DataFrame\n",
        "        Os resultados tratados já selecionando os 5 melhores, do pior para o melhor, utilizando como métrica o \n",
        "        valor do limite inferior do intervalo de confiança de 95%\n",
        "    \"\"\"\n",
        "    self.metrica = metrica  \n",
        "    cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats = n_repeats)\n",
        "    grid = GridSearchCV(self.modelo,parametros, scoring=metrica,cv=cv)\n",
        "    melhores = {'base':[],'reescala':[],'selecionador':[],'modelo':[],'parametros':[],self.metrica:[],'desvio_padrao':[]}\n",
        "    self.Xs = {}\n",
        "    self.ys = {}\n",
        "    for dados, base in lista_dados:\n",
        "      dados = dados.sample(frac=1).reset_index(drop=True)\n",
        "      y = dados[\"ICU\"]\n",
        "      X = dados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "      self.Xs = {base: X}\n",
        "      self.ys = {base: y}\n",
        "      _ = remove_corr().fit(X,y)\n",
        "      X = _.transform(X)\n",
        "      modelo_ = self.modelo.fit(X,y)\n",
        "      for i in range(selecao_menor,selecao_maior+1,passo):\n",
        "        if i > -100:\n",
        "          threshold_i = str(1+i/100)+'*mean'\n",
        "          seletor = SelectFromModel(modelo_, threshold=threshold_i).fit(X,y)\n",
        "          X_selecionado = seletor.transform(X)\n",
        "        else:\n",
        "          threshold_i = 'sem seleção adicional'\n",
        "          seletor = {'threshold':threshold_i,'colunas':X.columns}\n",
        "          X_selecionado = X.copy()\n",
        "        for item in lista_reescalas:\n",
        "          if item != 'nenhuma':\n",
        "            X_revisto = item.fit_transform(X_selecionado)\n",
        "          else:\n",
        "            X_revisto = X_selecionado\n",
        "          resultados= grid.fit(X_revisto,y)\n",
        "          desvio = resultados.cv_results_['std_test_score'][resultados.best_index_]\n",
        "          melhores['base'].append(base)\n",
        "          melhores['reescala'].append(item)\n",
        "          melhores['selecionador'].append(seletor)\n",
        "          melhores['modelo'].append(resultados)\n",
        "          melhores['parametros'].append(resultados.best_params_)\n",
        "          melhores[self.metrica].append(resultados.best_score_)\n",
        "          melhores['desvio_padrao'].append(desvio)\n",
        "          print(f'Finalizada iteração: seleção - {threshold_i}, reescala - {item}, base - {base}')\n",
        "\n",
        "    self.resultados = pd.DataFrame(melhores)\n",
        "    return self.classifica_resultados().tail()\n",
        "\n",
        "  def classifica_resultados(self, ordenar='inferior'): \n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ajusta os resultados num formato mais amigável e já ordena o campo informado, do menor para o maior\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    -------\n",
        "    ordenar: str\n",
        "        campo que desejamos ordenar no fim do tratamento\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    DataFrame\n",
        "        Os resultados tratados ordenados pelo campo definido em ordenar, do menor para o maior\n",
        "    \"\"\"\n",
        "    r = self.resultados.copy()\n",
        "    r['inferior']=r[self.metrica]-2*r['desvio_padrao']\n",
        "    r['superior']=r[self.metrica]+2*r['desvio_padrao']\n",
        "    colunas = r.columns.tolist()\n",
        "    colunas = colunas[2:]+colunas[:2]\n",
        "    r = r[colunas]\n",
        "    r['threshold']=\"\"\n",
        "    r['qtd_variaveis']=\"\"\n",
        "    for i in r.index.values:\n",
        "      if type(r.loc[i,'selecionador']) == dict:\n",
        "        r.loc[i,'threshold'] = r.loc[i,'selecionador']['threshold']\n",
        "        r.loc[i,'qtd_variaveis'] = len(r.loc[i,'selecionador']['colunas'])\n",
        "      else:\n",
        "        r.loc[i,'threshold'] = r.loc[i,'selecionador'].threshold\n",
        "        r.loc[i,'qtd_variaveis'] = len(r.loc[i,'selecionador'].get_feature_names_out())\n",
        "    for titulo in r.loc[0,'parametros'].keys():\n",
        "      r[titulo]=''\n",
        "      for i in r.index.values:\n",
        "        r.loc[i,titulo] = r.loc[i,'parametros'][titulo]\n",
        "    r.drop(['selecionador','modelo','parametros'], axis=1, inplace=True)\n",
        "    return r.sort_values(ordenar)\n",
        "\n",
        "  def cria_pipeline(self, indice=None):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    cria um pipeline com base nos resultados obtidos que fica salvo no atributo 'pipe'\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    -------\n",
        "    indice: str\n",
        "        indice da base de resultados que queremos utilizar na criação do pipeline. Se não for passado irá\n",
        "        utilizar o indice do maior limite inferior do intervalor de confiança de 95%.\n",
        "    \"\"\"\n",
        "    pipe = [('seletor1',remove_corr())]\n",
        "    \n",
        "    if indice:\n",
        "      self.indice = indice\n",
        "    else:\n",
        "      _ = self.classifica_resultados().reset_index().iloc[-1]\n",
        "      self.indice = _['index']\n",
        "    \n",
        "    if type(self.resultados.loc[self.indice,'selecionador']) != dict:\n",
        "      pipe.append(('seletor2',self.resultados.loc[self.indice,'selecionador']))\n",
        "    if self.resultados.loc[self.indice,'reescala'] != 'nenhuma':\n",
        "      pipe.append(('reescala',self.resultados.loc[self.indice,'reescala']))\n",
        "    pipe.append(('modelo',self.resultados.loc[self.indice,'modelo'].best_estimator_))\n",
        "    self.pipe = Pipeline(pipe)\n",
        "    self.base = self.resultados.loc[self.indice,'base']\n",
        "    return None\n",
        "\n",
        "  def roda_pipeline_metricas(self, random_state=None):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    com base no pipeline criado, plota a matriz de confusão, os reportes de classificação e o ROC AUC com base\n",
        "    em um split entre treino e dados aleatório da base definida como melhor \n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    -------\n",
        "    random_state: int\n",
        "        caso se queira definir uma semente para que se tenha o mesmo resultado ao se rodar novamente este método\n",
        "    \"\"\"\n",
        "    X_treino, X_teste, y_treino, y_teste = train_test_split(self.Xs[self.base], self.ys[self.base], \n",
        "                                                            stratify=self.ys[self.base], random_state=random_state)\n",
        "    self.pipe.fit(X_treino, y_treino)\n",
        "\n",
        "    ConfusionMatrixDisplay.from_predictions(y_teste, self.pipe.predict(X_teste))\n",
        "    plt.show()\n",
        "    print('\\n', classification_report(y_teste, self.pipe.predict(X_teste)))\n",
        "    print(f'ROC AUC: {roc_auc_score(y_teste, self.pipe.predict_proba(X_teste)[:,1]):.2%}')\n",
        "    \n",
        "    return None\n",
        " \n",
        "  def cria_modelo_final(self):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    salva o pipeline numa atibuto modelo_final que pode ser preservado para outras comparações ou ser salvo em um \n",
        "    arquivo\n",
        "    \"\"\"\n",
        "    self.modelo_final = self.pipe.fit(self.Xs[self.base], self.ys[self.base])\n",
        "    return self.modelo_final\n",
        "\n",
        "  def salva_modelo_final(self, nome_arquivo='modelo_final.joblib'):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    salva o modelo final em um arquivo joblib para utilização posterior ou para utilização na produção\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    --------\n",
        "    nome_arquivo: str\n",
        "        nome do arquivo onde ficará salvo o modelo\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    str\n",
        "        informa que o modelo foi salvo e o nome do arquivo\n",
        "    \"\"\"\n",
        "    dump(self.modelo_final, nome_arquivo)\n",
        "    return 'modelo salvo como: ' + nome_arquivo\n",
        "\n",
        "  def cria_salva_modelo_final(self, nome_arquivo='modelo_final.joblib'):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    salva o pipeline numa atibuto modelo_final que pode ser preservado para outras comparações. Também salva o \n",
        "    modelo final em um arquivo joblib para utilização posterior ou para utilização na produção\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    --------\n",
        "    nome_arquivo: str\n",
        "        nome do arquivo onde ficará salvo o modelo\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    str\n",
        "        informa que o modelo foi salvo e o nome do arquivo\n",
        "    \"\"\"\n",
        "    self.modelo_final = self.pipe.fit(self.Xs[self.base], self.ys[self.base])\n",
        "    dump(self.modelo_final, nome_arquivo)\n",
        "    return 'modelo salvo como: ' + nome_arquivo"
      ],
      "metadata": {
        "id": "QCaAKCpQgAcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}